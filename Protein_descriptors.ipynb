{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e607c1e1",
   "metadata": {},
   "source": [
    "# Obtaining protein descriptors\n",
    "***\n",
    "\n",
    "There are two information sources that are used for calculating the protein descriptors:\n",
    "1. The protein sequence\n",
    "2. DSSP data\n",
    "\n",
    "**Contents**\n",
    "\n",
    "1. [Protein sequence](#Protein-sequence)\n",
    "    1. [Getting the sequences](#Getting-the-sequences)\n",
    "    1. [Calculating descriptors from the sequence](#Calculating-descriptors-from-the-sequence)\n",
    "        1. [Sequence functions](#Sequence-functions)\n",
    "1. [DSSP data](#DSSP-data)\n",
    "    1. [Getting DSSP data](#Getting-DSSP-data)\n",
    "    1. [Processing DSSP files](#Processing-DSSP-files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98732ab",
   "metadata": {},
   "source": [
    "## Protein sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c5d9b7",
   "metadata": {},
   "source": [
    "### Getting the sequences\n",
    "It is possible to obtain the protein sequence from the `.pdb` files using the BioPandas python library, but instead they were procured by downloading the FASTA (text-based file format that stores nucleotide of amino acid sequences, represented in single letter codes) file from the Protein Data Bank that contained all the protein sequences in the database (link to file: https://ftp.wwpdb.org/pub/pdb/derived_data/pdb_seqres.txt). \n",
    "\n",
    "A function iterates over the lines of the file and returns a python dictionary that only contains the proteins that are present in the training dataset. This dictionary contains the following columns for every protein entry:\n",
    "* The PDB ID (`ID`)\n",
    "* Name of the protein (`name`)\n",
    "* Length of the sequence - includes all the chains in the protein (`length`)\n",
    "* Number of chains in the protein (`n_chains`)\n",
    "* Average number of aminoacids per chain (`aa/chain`)\n",
    "* The single letter code protein sequence as a string (`sequence`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3df476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_seq(seqence_file, valid_ids_list):\n",
    "    '''runs through the lines of a FASTA file, checks the ID of every entry \n",
    "    against a given list, and returns a dictionary that contains the\n",
    "    information for every protein in the list given (data_dict)'''\n",
    "\n",
    "    data_dict = {'ID': [], 'name': [], 'length': [], 'n_chains': [], 'aa/chain': [], 'sequence': []}\n",
    "    \n",
    "    seq_list = open(seqence_file, 'r')\n",
    "\n",
    "    line = next(seq_list).strip()\n",
    "    current_id = line[1:5]\n",
    "    name = line[(line.find('  ')+2):].strip()\n",
    "    chain_count = 1\n",
    "    seq = next(seq_list).strip()\n",
    "    \n",
    "    for line in seq_list:\n",
    "    \n",
    "        if line[0]=='>':\n",
    "            id_ = line[1:5]\n",
    "            if id_ not in valid_ids_list:\n",
    "                continue\n",
    "            else:\n",
    "                if id_==current_id:\n",
    "                    chain_count += 1\n",
    "                    line = next(seq_list)\n",
    "                    seq += line.strip()\n",
    "                else:\n",
    "                    data_dict['ID'].append(current_id)\n",
    "                    current_id = id_\n",
    "                    data_dict['name'].append(name)\n",
    "                    name = line[(line.find('  ')+2):].strip()\n",
    "                    data_dict['n_chains'].append(chain_count)\n",
    "                    data_dict['sequence'].append(seq)\n",
    "                    data_dict['length'].append(len(seq))\n",
    "                    data_dict['aa/chain'].append(round(len(seq)/chain_count, 2))\n",
    "                    chain_count = 1\n",
    "                    seq = ''\n",
    "        else:\n",
    "            seq+=line.strip()\n",
    "            \n",
    "    data_dict['ID'].append(current_id)\n",
    "    data_dict['name'].append(name)\n",
    "    data_dict['n_chains'].append(chain_count)\n",
    "    data_dict['sequence'].append(seq)\n",
    "    data_dict['length'].append(len(seq))\n",
    "    data_dict['aa/chain'].append(round(len(seq)/chain_count, 2))\n",
    "\n",
    "    seq_list.close()\n",
    "    return data_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32bcb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# contains one column ('ID') with all the PDB IDs that made it into the training set\n",
    "valid_ids_df = pd.read_csv(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\valid_ids.txt\")\n",
    "valid_ids = valid_ids_df['ID'].to_list() # makind it into a list\n",
    "\n",
    "# calling the parse_seq() function on the data\n",
    "seq_dict = parse_seq(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\pdb_seqres.txt\", valid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a120517",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_df = pd.DataFrame(seq_dict) # making the dictionary into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca157ab4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>length</th>\n",
       "      <th>n_chains</th>\n",
       "      <th>aa/chain</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10gs</td>\n",
       "      <td>GLUTATHIONE S-TRANSFERASE P1-1</td>\n",
       "      <td>418</td>\n",
       "      <td>2</td>\n",
       "      <td>209.0</td>\n",
       "      <td>PPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13gs</td>\n",
       "      <td>GLUTATHIONE S-TRANSFERASE</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>210.0</td>\n",
       "      <td>MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16pk</td>\n",
       "      <td>3-PHOSPHOGLYCERATE KINASE</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>415.0</td>\n",
       "      <td>EKKSINECDLKGKKVLIRVDFNVPVKNGKITNDYRIRSALPTLKKV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184l</td>\n",
       "      <td>T4 LYSOZYME</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185l</td>\n",
       "      <td>T4 LYSOZYME</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9602</th>\n",
       "      <td>8cpa</td>\n",
       "      <td>CARBOXYPEPTIDASE A</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>307.0</td>\n",
       "      <td>ARSTNTFNYATYHTLDEIYDFMDLLVAQHPELVSKLQIGRSYEGRP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9603</th>\n",
       "      <td>8gpb</td>\n",
       "      <td>GLYCOGEN PHOSPHORYLASE B</td>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "      <td>842.0</td>\n",
       "      <td>SRPLSDQEKRKQISVRGLAGVENVTELKKNFNRHLHFTLVKDRNVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9604</th>\n",
       "      <td>966c</td>\n",
       "      <td>MMP-1</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>RWEQTHLTYRIENYTPDLPRADVDHAIEKAFQLWSNVTPLTFTKVS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9605</th>\n",
       "      <td>9hvp</td>\n",
       "      <td>HIV-1 PROTEASE</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>PQITLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMNLPGRWKPKM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>9icd</td>\n",
       "      <td>ISOCITRATE DEHYDROGENASE</td>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "      <td>416.0</td>\n",
       "      <td>MESKVVVPAQGKKITLQNGKLNVPENPIIPYIEGDGIGVDVTPAML...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9607 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                            name  length  n_chains  aa/chain  \\\n",
       "0     10gs  GLUTATHIONE S-TRANSFERASE P1-1     418         2     209.0   \n",
       "1     13gs       GLUTATHIONE S-TRANSFERASE     420         2     210.0   \n",
       "2     16pk       3-PHOSPHOGLYCERATE KINASE     415         1     415.0   \n",
       "3     184l                     T4 LYSOZYME     164         1     164.0   \n",
       "4     185l                     T4 LYSOZYME     164         1     164.0   \n",
       "...    ...                             ...     ...       ...       ...   \n",
       "9602  8cpa              CARBOXYPEPTIDASE A     307         1     307.0   \n",
       "9603  8gpb        GLYCOGEN PHOSPHORYLASE B     842         1     842.0   \n",
       "9604  966c                           MMP-1     157         1     157.0   \n",
       "9605  9hvp                  HIV-1 PROTEASE     198         2      99.0   \n",
       "9606  9icd        ISOCITRATE DEHYDROGENASE     416         1     416.0   \n",
       "\n",
       "                                               sequence  \n",
       "0     PPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKAS...  \n",
       "1     MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA...  \n",
       "2     EKKSINECDLKGKKVLIRVDFNVPVKNGKITNDYRIRSALPTLKKV...  \n",
       "3     MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...  \n",
       "4     MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...  \n",
       "...                                                 ...  \n",
       "9602  ARSTNTFNYATYHTLDEIYDFMDLLVAQHPELVSKLQIGRSYEGRP...  \n",
       "9603  SRPLSDQEKRKQISVRGLAGVENVTELKKNFNRHLHFTLVKDRNVA...  \n",
       "9604  RWEQTHLTYRIENYTPDLPRADVDHAIEKAFQLWSNVTPLTFTKVS...  \n",
       "9605  PQITLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMNLPGRWKPKM...  \n",
       "9606  MESKVVVPAQGKKITLQNGKLNVPENPIIPYIEGDGIGVDVTPAML...  \n",
       "\n",
       "[9607 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03159c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataFrame is saved to a .csv file\n",
    "seq_dict_df.to_csv(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\CSVs\\\\sequences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d01558",
   "metadata": {},
   "source": [
    "### Calculating descriptors from the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d4583",
   "metadata": {},
   "source": [
    "A series of functions are writtend to calculate the following descriptors for the proteins from their sequence:\n",
    "* Molecular weight of protein (`prot_MW()`)\n",
    "* Sum of the solvent accessible surface area (SASA) of amino acids (might be different from actual SASA of the protein) (`tot_aa_SASA()`)\n",
    "* Total Van Der Waals volume of the amino acids in the sequence (`tot_VWvol()`)\n",
    "* The counts of all amino acids in the sequence (`count_aa()`)\n",
    "* The percentage of all amino acids in the sequence (`percent_aa()`)\n",
    "* Percentages of amino acids with various proterties - polar, apolar, acidic etc... (more details in Descriptions.pdf) (`percents()`)\n",
    "* Total topological surface area from amino acids in the sequence (`tot_aa_TPSA()`)\n",
    "* Polar and different types of apolar surface area (`pol_SA()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98abbb9",
   "metadata": {},
   "source": [
    "#### Sequence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf71256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prot_MW(seq):\n",
    "    '''calculates molecular weight (MW) from sequence, returns MW in kiloDaltons (kDa)'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    MW = 0\n",
    "    aa = {'A': 89.0935,\n",
    "        'R': 174.2017, \n",
    "        'N': 132.1184, \n",
    "        'D': 133.1032, \n",
    "        'C': 121.159,  \n",
    "        'E': 147.1299,\n",
    "        'Q': 146.1451, \n",
    "        'G': 75.0669, \n",
    "        'H': 155.1552, \n",
    "        'I': 131.1736, \n",
    "        'L': 131.1736, \n",
    "        'K': 146.1882, \n",
    "        'M': 149.2124, \n",
    "        'F': 165.19, \n",
    "        'P': 115.131, \n",
    "        'S': 105.093, \n",
    "        'T': 119.1197, \n",
    "        'W': 204.2262, \n",
    "        'Y': 181.1894, \n",
    "        'V': 117.1469}\n",
    "    \n",
    "    for a in sequence:\n",
    "        try:\n",
    "            MW += aa[a]\n",
    "        except KeyError:\n",
    "            MW += 136.9008 # if nonstandard aa, add average wt of aa\n",
    "    return round(MW/1000, 2)\n",
    "    \n",
    "    \n",
    "def tot_aa_SASA(seq):\n",
    "    '''calculates the sum of solvent accessible surface area \n",
    "    of the amino acids in the sequence, returns it in A**2 (angstrom sqr). \n",
    "    Source of data in 'aa' dictionary:\n",
    "    https://www.researchgate.net/figure/Average-SASA-values-for-amino-acids_tbl5_24032510'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    SASA = 0\n",
    "    \n",
    "    # aa SASA\n",
    "    aa = {'A': 209.02,\n",
    "        'R': 335.73, \n",
    "        'N': 259.85, \n",
    "        'D': 257.99, \n",
    "        'C': 240.50,  \n",
    "        'E': 285.03,\n",
    "        'Q': 286.75, \n",
    "        'G': 185.15, \n",
    "        'H': 290.04, \n",
    "        'I': 273.46, \n",
    "        'L': 278.44, \n",
    "        'K': 303.43, \n",
    "        'M': 291.52, \n",
    "        'F': 311.30, \n",
    "        'P': 235.41, \n",
    "        'S': 223.04, \n",
    "        'T': 243.55, \n",
    "        'W': 350.68, \n",
    "        'Y': 328.82, \n",
    "        'V': 250.09}\n",
    "    \n",
    "    for a in sequence:\n",
    "        try:\n",
    "            SASA+=aa[a]\n",
    "        except KeyError:\n",
    "            SASA+=271.99 # if non-standard aa, add average value\n",
    "    return round(SASA, 2)\n",
    "        \n",
    "        \n",
    "def tot_VWvol(seq):\n",
    "    '''calculates the van der waals volume (VWV) of the \n",
    "    amino acids in the sequence, returns it in A**3 (angstrom cubed). \n",
    "    Source of data in 'aa' dictionary:\n",
    "    http://proteinsandproteomics.org/content/free/tables_1/table08.pdf'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    VWV = 0\n",
    "    aa = {'A': 67,\n",
    "        'R': 148, \n",
    "        'N': 96, \n",
    "        'D': 91, \n",
    "        'C': 86,  \n",
    "        'E': 109,\n",
    "        'Q': 114, \n",
    "        'G': 48, \n",
    "        'H': 118, \n",
    "        'I': 124, \n",
    "        'L': 124, \n",
    "        'K': 135, \n",
    "        'M': 124, \n",
    "        'F': 135, \n",
    "        'P': 90, \n",
    "        'S': 73, \n",
    "        'T': 93, \n",
    "        'W': 163, \n",
    "        'Y': 141, \n",
    "        'V': 105}\n",
    "    \n",
    "    for a in sequence:\n",
    "        try:\n",
    "            VWV+=aa[a]\n",
    "        except KeyError:\n",
    "            VWV+=109 # if non-standard aa, add average value\n",
    "    return VWV\n",
    "        \n",
    "        \n",
    "def count_aa(seq):\n",
    "    '''calculates the number of every aa in the sequence, \n",
    "    does not count non-standard aa. Returns a dict of the values ({aa: val})'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    aa = {'nA': 0,\n",
    "        'nR': 0, \n",
    "        'nN': 0, \n",
    "        'nD': 0, \n",
    "        'nC': 0,  \n",
    "        'nE': 0,\n",
    "        'nQ': 0, \n",
    "        'nG': 0, \n",
    "        'nH': 0, \n",
    "        'nI': 0, \n",
    "        'nL': 0, \n",
    "        'nK': 0,\n",
    "        'nM': 0, \n",
    "        'nF': 0, \n",
    "        'nP': 0, \n",
    "        'nS': 0, \n",
    "        'nT': 0, \n",
    "        'nW': 0, \n",
    "        'nY': 0, \n",
    "        'nV': 0}\n",
    "    \n",
    "    for a in seq:\n",
    "        try:\n",
    "            aa['n'+a]+=1\n",
    "        except KeyError:\n",
    "            continue # if non-standard aa, don't count\n",
    "    return aa\n",
    "    \n",
    "def percent_aa(seq):\n",
    "    '''calculates the percentage of every aa in the sequence, \n",
    "    does not count non-standard aa. Returns a dict of the values ({aa: val})'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    counts = count_aa(sequence)\n",
    "    seq_len = len(seq)\n",
    "    aa = {'%A': 0,\n",
    "        '%R': 0, \n",
    "        '%N': 0, \n",
    "        '%D': 0, \n",
    "        '%C': 0,  \n",
    "        '%E': 0,\n",
    "        '%Q': 0, \n",
    "        '%G': 0, \n",
    "        '%H': 0, \n",
    "        '%I': 0, \n",
    "        '%L': 0, \n",
    "        '%K': 0,\n",
    "        '%M': 0, \n",
    "        '%F': 0, \n",
    "        '%P': 0, \n",
    "        '%S': 0, \n",
    "        '%T': 0, \n",
    "        '%W': 0, \n",
    "        '%Y': 0, \n",
    "        '%V': 0}\n",
    "    for an in counts.keys():\n",
    "        a = an[-1]\n",
    "        aa['%'+a]=round((counts[an]/seq_len)*100, 2)\n",
    "    return aa\n",
    "    \n",
    "    \n",
    "def percents(seq):\n",
    "    '''calculates percentages of different types of amino acids'''\n",
    "    \n",
    "    perc = percent_aa(seq)\n",
    "    apol_aa = ['A', 'V', 'P', 'L', 'I', 'M']\n",
    "    pol_unchar = ['S', 'T', 'C', 'N', 'Q']\n",
    "    pol_ch = ['D', 'E', 'K', 'R', 'H']\n",
    "    pol_ch_basic = ['K', 'R', 'H']\n",
    "    pol_ch_acid = ['D', 'E']\n",
    "    aromatic = ['F', 'W', 'Y']\n",
    "    aliphatic = ['A', 'G', 'H', 'I', 'L', 'P', 'V']\n",
    "    hydrox = ['S', 'T']\n",
    "    amidic = ['N', 'Q']\n",
    "    w_S = ['C', 'M']\n",
    "\n",
    "    pol = {'%polar': 0, # % of *a*polar (error persisted until \n",
    "                        # final creation of the training data) aa\n",
    "          '%pol_unch': 0, # % of polar uncharged aa\n",
    "          '%pol_ch': 0, # % of polar charged aa\n",
    "          '%pol_ch_basic': 0, # % of polar charged basic aa\n",
    "          '%pol_ch_acid': 0, # % of polar charged acidic aa\n",
    "          '%aromatic': 0, # % of aromatic aa\n",
    "          '%aliphatic': 0, # % of aliphatic aa\n",
    "          '%hydrox': 0, # % of hydroxylic aa\n",
    "          '%amidic': 0, # % of amidic aa\n",
    "          '%w_S': 0} # % of aa that contain a sulphur atom\n",
    "    \n",
    "    for a in apol_aa:\n",
    "        pol['%polar']+=perc['%'+a]\n",
    "    for a in pol_unchar:\n",
    "        pol['%pol_unch']+=perc['%'+a]\n",
    "    for a in pol_ch:\n",
    "        pol['%pol_ch']+=perc['%'+a]\n",
    "    for a in pol_ch_basic:\n",
    "        pol['%pol_ch_basic']+=perc['%'+a]\n",
    "    for a in pol_ch_acid:\n",
    "        pol['%pol_ch_acid']+=perc['%'+a]\n",
    "    for a in aromatic:\n",
    "        pol['%aromatic']+=perc['%'+a]\n",
    "    for a in aliphatic:\n",
    "        pol['%aliphatic']+=perc['%'+a]\n",
    "    for a in hydrox:\n",
    "        pol['%hydrox']+=perc['%'+a]\n",
    "    for a in amidic:\n",
    "        pol['%amidic']+=perc['%'+a]\n",
    "    for a in w_S:\n",
    "        pol['%w_S']+=perc['%'+a]\n",
    "    \n",
    "    pol.update((x, round(y, 3)) for x, y in pol.items())\n",
    "    return pol\n",
    "        \n",
    "        \n",
    "def tot_aa_TPSA(seq):\n",
    "    '''calculates the total topological polar surface area (TPSA)\n",
    "    of all amino acids. Returns TPSA in A**2 (angsrom sqared). \n",
    "    Source of data in 'aa' dictionary: PubChem - https://pubchem.ncbi.nlm.nih.gov/'''\n",
    "    \n",
    "    sequence = seq.upper()\n",
    "    TPSA = 0\n",
    "    aa = {'A': 63.3,\n",
    "        'R': 128, \n",
    "        'N': 106, \n",
    "        'D': 101, \n",
    "        'C': 64.3,  \n",
    "        'E': 101,\n",
    "        'Q': 106, \n",
    "        'G': 63.3, \n",
    "        'H': 92, \n",
    "        'I': 63.3, \n",
    "        'L': 63.3, \n",
    "        'K': 89.3, \n",
    "        'M': 88.6, \n",
    "        'F': 63.3, \n",
    "        'P': 49.3, \n",
    "        'S': 83.6, \n",
    "        'T': 83.6, \n",
    "        'W': 79.1, \n",
    "        'Y': 83.6, \n",
    "        'V': 63.3}\n",
    "    \n",
    "    for a in sequence:\n",
    "        try:\n",
    "            TPSA+=aa[a]\n",
    "        except KeyError:\n",
    "            TPSA+=81.76 # if non-standard aa, add average PSA\n",
    "    return round(TPSA, 3)\n",
    "    \n",
    "    \n",
    "def pol_SA(seq):\n",
    "    '''calculates polar and apolar surface area. Returns dict with values\n",
    "    for each area type in A**2 (angstrom sqared) ({area: val})'''\n",
    "\n",
    "    sequence = seq.upper()\n",
    "    count = count_aa(sequence)\n",
    "    \n",
    "    pol = {'apolar_SA': 0, \n",
    "          'pol_unch_SA': 0, \n",
    "          'pol_ch_SA': 0, \n",
    "          'pol_ch_basic_SA': 0, \n",
    "          'pol_ch_acid_SA': 0}\n",
    "    \n",
    "    apol_aa = ['A', 'V', 'P', 'L', 'I', 'M']\n",
    "    pol_unchar = ['S', 'T', 'C', 'N', 'Q']\n",
    "    pol_ch = ['D', 'E', 'K', 'R', 'H']\n",
    "    pol_ch_basic = ['K', 'R', 'H']\n",
    "    pol_ch_acid = ['D', 'E']\n",
    "    \n",
    "    # aa SASA\n",
    "    aa = {'A': 209.02,\n",
    "        'R': 335.73, \n",
    "        'N': 259.85, \n",
    "        'D': 257.99, \n",
    "        'C': 240.50,  \n",
    "        'E': 285.03,\n",
    "        'Q': 286.75, \n",
    "        'G': 185.15, \n",
    "        'H': 290.04, \n",
    "        'I': 273.46, \n",
    "        'L': 278.44, \n",
    "        'K': 303.43, \n",
    "        'M': 291.52, \n",
    "        'F': 311.30, \n",
    "        'P': 235.41, \n",
    "        'S': 223.04, \n",
    "        'T': 243.55, \n",
    "        'W': 350.68, \n",
    "        'Y': 328.82, \n",
    "        'V': 250.09}\n",
    "    \n",
    "    for a in apol_aa:\n",
    "        pol['apolar_SA']+=count['n'+a]*aa[a]\n",
    "    for a in pol_unchar:\n",
    "        pol['pol_unch_SA']+=count['n'+a]*aa[a]\n",
    "    for a in pol_ch:\n",
    "        pol['pol_ch_SA']+=count['n'+a]*aa[a]\n",
    "    for a in pol_ch_basic:\n",
    "        pol['pol_ch_basic_SA']+=count['n'+a]*aa[a]\n",
    "    for a in pol_ch_acid:\n",
    "        pol['pol_ch_acid_SA']+=count['n'+a]*aa[a]\n",
    "    \n",
    "    pol.update((x, round(y, 3)) for x, y in pol.items())\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ac614",
   "metadata": {},
   "source": [
    "## DSSP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742c464",
   "metadata": {},
   "source": [
    "The DSSP data is retrieved from a web server with the use of an API (https://www3.cmbi.umcn.nl/xssp/api/), by querying the PDB IDs from the `valid_ids` list.\n",
    "\n",
    "Most of the code below is taken from the example code provided in the API (https://www3.cmbi.umcn.nl/xssp/api/examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008036a",
   "metadata": {},
   "source": [
    "### Getting DSSP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec5b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example client takes a PDB ID, sends it to the REST service, which retrieves the\n",
    "DSSP data. The DSSP data is then output to the console.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_dssp(pdb_id):\n",
    "    # Read the pdb id into a variable\n",
    "    data = {'data': pdb_id}\n",
    "    rest_url = 'https://www3.cmbi.umcn.nl/xssp/'\n",
    "    \n",
    "    # Send a request to the server to retrieve the dssp data from the pdb id.\n",
    "    # If an error occurs, an exception is raised and the program exits. If the\n",
    "    # request is successful, the id of the job running on the server is\n",
    "    # returned.\n",
    "    url_create = '{}api/create/pdb_id/dssp/'.format(rest_url)\n",
    "    r = requests.post(url_create, data=data)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    job_id = json.loads(r.text)['id']\n",
    "\n",
    "    \n",
    "    # Loop until the job running on the server has finished, either successfully\n",
    "    # or due to an error.\n",
    "    ready = False\n",
    "    while not ready:\n",
    "        url_status = '{}api/status/pdb_id/dssp/{}/'.format(rest_url, job_id)\n",
    "        r = requests.get(url_status)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        status = json.loads(r.text)['status']\n",
    "  \n",
    "        # If the status equals SUCCESS, exit out of the loop by changing the\n",
    "        # condition ready. This causes the code to drop into the `else` block\n",
    "        # below.\n",
    "        #\n",
    "        # If the status equals either FAILURE or REVOKED, an exception is raised\n",
    "        # containing the error message. The program exits.\n",
    "        #\n",
    "        # Otherwise, wait for five seconds and start at the beginning of the\n",
    "        # loop again.\n",
    "        if status == 'SUCCESS':\n",
    "            ready = True\n",
    "        elif status in ['FAILURE', 'REVOKED']:\n",
    "            raise Exception(json.loads(r.text)['message'])\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        # Requests the result of the job. If an error occurs an exception is\n",
    "        # raised and the program exits. If the request is successful, the result\n",
    "        # is returned.\n",
    "        url_result = '{}api/result/pdb_id/dssp/{}/'.format(rest_url, job_id)\n",
    "        r = requests.get(url_result)\n",
    "        r.raise_for_status()\n",
    "        result = json.loads(r.text)['result']\n",
    "\n",
    "        # Return the result to the caller, which prints it to the screen.\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76f30a",
   "metadata": {},
   "source": [
    "The `get_dssp()` function above is used to retrieve the the DSSP data from PDB IDs, which then is written to files by the the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a062b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dssp(dssp, ID):\n",
    "    with open(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\DSSPs\\\\{}.dssp\".format(ID), 'w') as file_:\n",
    "        file_.write(dssp)\n",
    "\n",
    "for ID in valid_ids:\n",
    "    write_dssp(get_dssp(ID), ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648bced3",
   "metadata": {},
   "source": [
    "### Processing DSSP files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538aa65",
   "metadata": {},
   "source": [
    "After the DSSP files were downloaded and written into files, the files were processed to extract the useful information. \n",
    "\n",
    "The following code goes systematically through the DSSP files and creates a dictionary that is then converted to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6496660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dssps(dssp_directory):\n",
    "    '''This function takes in a path to a directory with dssp files and builds a \n",
    "    dictionary containing all the values extracted from their respective files \n",
    "    (see 'dssp_dict' dictionary keys for details, and descriptions.pdf\n",
    "    for explanations of each entry)'''\n",
    "    \n",
    "    # dictionary with all the descriptors and fields that will be\n",
    "    # used in training \n",
    "    dssp_dict = {\n",
    "    'ID': [], \n",
    "    'tot_SS_bri': [], \n",
    "    'intrachain_SS_bri': [], \n",
    "    'interchain_SS_bri': [], \n",
    "    'asa': [], \n",
    "    'tot_O(I)>H-N(J)_H_bonds': [], \n",
    "    'O(I)>H-N(J)_H_bonds%': [], \n",
    "    'parallel_bri_H_bonds': [], \n",
    "    'parallel_bri_H_bonds%': [], \n",
    "    'antiparallel_bri_H_bonds': [], \n",
    "    'antiparallel_bri_H_bonds%': [], \n",
    "    'O(I)>H-N(I-5)_H_bonds': [] ,\n",
    "    'O(I)>H-N(I-5)_H_bonds%': [], \n",
    "    'O(I)>H-N(I-4)_H_bonds': [], \n",
    "    'O(I)>H-N(I-4)_H_bonds%': [], \n",
    "    'O(I)>H-N(I-3)_H_bonds': [], \n",
    "    'O(I)>H-N(I-3)_H_bonds%': [], \n",
    "    'O(I)>H-N(I-2)_H_bonds': [], \n",
    "    'O(I)>H-N(I-2)_H_bonds%': [], \n",
    "    'O(I)>H-N(I-1)_H_bonds': [], \n",
    "    'O(I)>H-N(I-1)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+0)_H_bonds': [], \n",
    "    'O(I)>H-N(I+0)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+1)_H_bonds': [], \n",
    "    'O(I)>H-N(I+1)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+2)_H_bonds': [], \n",
    "    'O(I)>H-N(I+2)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+3)_H_bonds': [], \n",
    "    'O(I)>H-N(I+3)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+4)_H_bonds': [], \n",
    "    'O(I)>H-N(I+4)_H_bonds%': [], \n",
    "    'O(I)>H-N(I+5)_H_bonds': [], \n",
    "    'O(I)>H-N(I+5)_H_bonds%': []\n",
    "    }\n",
    "\n",
    "    # iterating through the files in the given directory\n",
    "    for filename in os.listdir(dssp_directory):\n",
    "        \n",
    "        file_ = os.path.join(dssp_directory, filename)\n",
    "        with open(file_, 'r') as f:\n",
    "            \n",
    "            # keeping track of line count with a variable 'c'\n",
    "            c = 0\n",
    "            for l in f:\n",
    "                c+=1\n",
    "                sp = l.split()  # splitting each line into its elements\n",
    "                \n",
    "                # depending on what line the iteration is on, different \n",
    "                # elements of the line will be added to the dictionary fields\n",
    "                if c == 3:\n",
    "                    dssp_dict['ID'].append(l.split()[-2].strip().lower())\n",
    "                elif c == 7:\n",
    "                    dssp_dict['tot_SS_bri'].append(int(sp[2]))\n",
    "                    dssp_dict['intrachain_SS_bri'].append(int(sp[3]))\n",
    "                    dssp_dict['interchain_SS_bri'].append(int(sp[4]))\n",
    "                elif c == 8:\n",
    "                    dssp_dict['asa'].append(float(l.split()[0]))\n",
    "                elif c == 9:\n",
    "                    dssp_dict['tot_O(I)>H-N(J)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(J)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 10:\n",
    "                    dssp_dict['parallel_bri_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['parallel_bri_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 11:\n",
    "                    dssp_dict['antiparallel_bri_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['antiparallel_bri_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 12:\n",
    "                    dssp_dict['O(I)>H-N(I-5)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I-5)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 13:\n",
    "                    dssp_dict['O(I)>H-N(I-4)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I-4)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 14:\n",
    "                    dssp_dict['O(I)>H-N(I-3)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I-3)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 15:\n",
    "                    dssp_dict['O(I)>H-N(I-2)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I-2)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 16:\n",
    "                    dssp_dict['O(I)>H-N(I-1)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I-1)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 17:\n",
    "                    dssp_dict['O(I)>H-N(I+0)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+0)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 18:\n",
    "                    dssp_dict['O(I)>H-N(I+1)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+1)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 19:\n",
    "                    dssp_dict['O(I)>H-N(I+2)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+2)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 20:\n",
    "                    dssp_dict['O(I)>H-N(I+3)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+3)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 21:\n",
    "                    dssp_dict['O(I)>H-N(I+4)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+4)_H_bonds%'].append(float(sp[1]))\n",
    "                elif c == 22:\n",
    "                    dssp_dict['O(I)>H-N(I+5)_H_bonds'].append(int(sp[0]))\n",
    "                    dssp_dict['O(I)>H-N(I+5)_H_bonds%'].append(float(sp[1]))\n",
    "    return dssp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143ac9b",
   "metadata": {},
   "source": [
    "A dictionary is made (`dssp_dict`) and then converted to a Pandas DataFrame (`dssp_df`), which is saved as a .csv file, that will be used later in the assembly of the final dataset for trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c6caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssp_dict = parse_dssps(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\DSSPs\\\\\")\n",
    "\n",
    "dssp_df = pd.DataFrame.from_dict(dssp_dict)\n",
    "dssp_df.to_csv(\"C:\\\\Users\\\\Ieremita Emanuel\\\\Desktop\\\\CS_project\\\\CSVs\\\\dssp_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
